# RAG basics using a self hosted OpenAI compatible LLM server

The notebook in this repository contains all of the code from my Medium post [**RAG basics using a self hosted OpenAI compatible LLM server**](https://medium.com/@penkow/rag-basics-using-a-self-hosted-openai-compatible-llm-server-31574caf9572)

You will find out how to:

- Install Langchain and FAISS
- Run an OpenAI compatible LLM server
- Self-host qunatized Llama 2 7b on CPU
- Create embeddings from the content of a web page
- Use vector search and Llama 2 to perform RAG
- See the difference between normal and RAG based model prompt 

Happy Coding! ðŸ™‚